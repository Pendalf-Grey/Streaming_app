                            СТРУКТУРА ПРОЕКТА

______________________________________________________

                            СОСТАВНЫЕ ЧАСТИ И ОСНОВНЫЕ ТЕХНОЛОГИИ

---- Микросервисы / DDD

Frontend (
React) [регистрация и вход в систему / просмотр потоков других юзеров / создание своего потока / участие в общем чате к трансляции]
Backend (FastAPI) [аутентификация, авторизация / менеджер потоков / онлайн чат / API для получения инфы о юзере]
Streaming Server (Nginx-RTMP)
DataBase (MongoDB)
Kafka - основная шина для передачи даееых между микросервисами.


                            НАЗНАЧЕНИЕ ПАПОК И ФАЙЛОВ

streaming_app_authorization/: Основная папка, содержащая код вашего приложения.
   
      schemas/: Сами пишем файлы с Pydantic-схемами, которые используются для валидации входящих данных и сериализации выходящих.
      routes/: Содержит определения маршрутов (эндпоинтов) вашего API.
      services/: Папка для бизнес-логики, где вы можете обрабатывать данные и взаимодействие с базой данных.
      database/: Настройки подключения к базе данных, ORM-определения и другие базы данных.
      utils/: Утилиты и вспомогательные функции для вашего приложения.

      
tests/: Папка для тестов, где хранятся ваши тестовые файлы. 
Каждый файл тестов должен соответствовать или быть связанным с основной логикой приложения, которую он тестирует.

      __init__.py
      test_authorization.http
      test_main.http
      test_users.http

docker_compose/: Папка для файлов, связанных с Докером

      storage.yaml
      Makefile

.gitignore: Указывает, какие файлы или папки следует игнорировать при использовании Git.
README.md: Документация о вашем проекте, его установке, использовании и других важных деталях.

Dockerfile - файл Докера

poetry.lock - что-то для poetry

pyproject.toml - зависимости для poetry

.env - файл с конфиденциальной инфой

.env.example - предварительный файл с конфиденциальной инфой


/
                            КРАТКО О _init__.py

Основные назначения файла __init__.py

      Определение пакета: Наличие файла __init__.py в директории делает эту директорию пакетом Python. Без этого файла Python
      не будет распознавать директорию как пакет, и вы не сможете импортировать модули из этой директории.
      
      Инициализация пакета: Когда вы импортируете пакет, Python выполняет код, содержащийся в __init__.py. Это может быть
      полезно для выполнения инициализации пакета или определения конфигурации.
      
      Упрощение импорта: Вы можете использовать файл __init__.py для управления, что будет доступно при импорте пакета.
      Например, вы можете определить, какие классы или функции экспортировать, что позволяет использовать сокращенные пути
      импорта
.

                           О Makefile (сначала как понял я)

В работе с реляционной БД, если мы дёргали в коде файл:

      models.py

то нам нужно было выполнить миграции 
для изменения таблиц в БД. 

Здесь, если мы дёргаем:

      main.o или utils.o

нужно выполнить команду:

      make app 

для внесения изменений в Докер-файл.


Makefile — это специальный файл, используемый инструментом make для автоматизации сборки и управления проектами. Он содержит набор правил и инструкций, которые определяют, как компилировать и связывать программы, а также выполнять другие задачи, такие как тестирование или развертывание.

Вот основные компоненты Makefile:

      Цели (Targets): Это имена файлов или действий, которые вы хотите создать или выполнить. Например, цель может быть именем исполняемого файла, который вы хотите скомпилировать.
      
      Зависимости (Dependencies): Это файлы, от которых зависит цель. Если зависимости изменяются, make будет знать, что нужно пересобрать цель.
      
      Команды (Commands): Это команды, которые будут выполнены для создания цели. Они обычно начинаются с табуляции и могут включать команды компиляции, копирования файлов и другие действия.
      Пример простого Makefile:
      
            makefile
            
            # Определение компилятора и флагов
            CC = gcc
            CFLAGS = -Wall
            
            # Цель по умолчанию
            all: myapp
            
            # Правило для создания исполняемого файла myapp
            myapp: main.o utils.o
                $(CC) $(CFLAGS) -o myapp main.o utils.o
            
            # Правила для создания объектных файлов
            main.o: main.c
                $(CC) $(CFLAGS) -c main.c
            
            utils.o: utils.c
                $(CC) $(CFLAGS) -c utils.c
            
            # Очистка сгенерированных файлов
            clean:
                rm -f myapp *.o
            В этом примере:
      
Цель all зависит от myapp, что означает, что при запуске make будет собираться myapp.

myapp зависит от main.o и utils.o, и если они изменятся, make пересоберет myapp.

Команды для компиляции и связывания указаны под каждой целью.

Цель clean позволяет удалить сгенерированные файлы.
Использование Makefile позволяет упростить процесс сборки и управления проектами, особенно в больших проектах с множеством файлов и зависимостей.

Запись myapp: main.o utils.o в Makefile определяет цель myapp, которая зависит от двух файлов: main.o и utils.o. Это означает, что для того чтобы создать (или обновить) исполняемый файл myapp, необходимо сначала убедиться, что объектные файлы main.o и utils.o актуальны.

Команда, следующая за этой записью:
      
      $(CC) $(CFLAGS) -o myapp main.o utils.o
      указывает, как именно будет создан исполняемый файл myapp. Здесь:
      
      $(CC) — это переменная, содержащая имя компилятора (в данном случае gcc).
      
      $(CFLAGS) — это переменная, содержащая флаги компиляции (например, -Wall для включения всех предупреждений).
      
      -o myapp указывает, что выходной файл должен называться myapp.

main.o и utils.o — это объектные файлы, которые будут связаны для создания исполняемого файла.
Таким образом, если вы запустите команду make, инструмент make проверит, существуют ли main.o и utils.o, и если они были изменены с момента последней сборки, он выполнит указанную команду для создания или обновления myapp. Если объектные файлы не изменялись, make пропустит эту команду, так как нет необходимости пересобирать myapp.



                            ЗАВИСИМОСТИ

Poetry

Активация: poetry shell



                            КОНФИГУРАЦИОННЫЙ ФАЙЛ .env

Текстовый файл, служит для хранения кредов и конфигурационной информации в проекте.

Чтобы импортировать инфу из .env в прочие файлы приложения - нужно установить:

      pip install dotenv

Пример .env файла:

      DATABASE_URL=mysql://user:password@localhost/dbname
      SECRET_KEY=your_secret_key

.

                            НАЧАЛЬНАЯ СТРУКТУРА ПРОЕКТА

      fastApiProject_Streaming/
      ├── streaming_app/
      │ ├── __init__.py # Инициализационный файл пакета
      │ ├── main.py # Основной файл приложения FastAPI
      │ ├── schemas/ # Папка для Pydantic схем
      │ │ ├── __init__.py
      │ │ └── user.py # Схемы для пользователя
      │ ├── routes/ # Папка для маршрутов API
      │ │ ├── __init__.py
      │ │ └── user.py # Маршруты для работы с пользователями
      │ ├── services/ # Папка для бизнес-логики
      │ │ ├── __init__.py
      │ │ └── authorization_service.py # Логика для работы с авторизацией
      │ ├── database/ # Папка для работы с базой данных
      │ │ ├── __init__.py
      │ │ └── db.py # Настройки подключения к БД и интерпретация моделей
      │ └── utils/ # Утилитарные функции
      │ ├── __init__.py
      │ └── helpers.py # Вспомогательные функции
      ├── tests/ # Папка для тестов
      │ ├── __init__.py
      │ ├── test_main.py # Тесты для main.py
      │ └── test_users.py # Тесты для пользовательских маршрутов
      ├── .gitignore # Файл для исключения из Git
      └── README.md # Описание проекта
.


                        БЕКЕНД

______________________________________________________


                        БАЗА ДАННЫХ

MongoDB


                        STREAMING SERVER

Nginx-RTMP

Вот пример базовой конфигурации для Nginx с модулем RTMP, 
который может помочь вам начать

    rtmp {
       server {
           listen 1935;
           chunk_size 4096;
   
           application live {
               live on;
               record off;
           }
       }
    }
   
    http {
       server {
           listen 80;
   
           location / {
               # Web interface, provide your own frontend here
               root html;
               index index.html index.htm;
           }
   
           # HLS configuration if required
           location /hls {
               types {
                   application/vnd.apple.mpegurl m3u8;
                   video/mp2t ts;
               }
               root /tmp;
               add_header Cache-Control no-cache;
           }
       }
    }

.


                        АУТЕНТИФИКАЦИЯ И АВТОРИЗАЦИЯ

Буду использовать строгую и нестрогую аутентификацию.

Нестрогая --- аутентификация с помощью Google, VK и пр.
Строгая --- регистрация, аутентификация + авторизация в Streaming_app
Технологии: OAuth2 (нестрогая) + JWT (строгая)

Использую библиотеку AuthX, т.к. есть пример на видео. Она поддерживает JWT, OAuth2, MongoDB.

Всё то же самое поддерживает и встроенная в FastAPI библиотека Users - она может помочь при реализации
более сложной логики авторизации (При желании потом перейду на неё)


                        POETRY

Чтобы заменить pip на poetry в вашем проекте, вы можете следовать приведённым ниже шагам:

      1. Установка poetry
         Если poetry ещё не установлен, установите его с помощью следующей команды:
      
      curl -sSL https://install.python-poetry.org | python3 -
      
      Или, при желании, вы можете установить его с помощью pip:
      pip install poetry
      
      2. Инициализация poetry в проекте
         Перейдите в корневую директорию вашего проекта и инициализируйте poetry:
         cd ваш_проект
         poetry init
      
      Следуйте инструкциям в терминале. poetry предложит вам ввести зависимости, если они у вас есть, или можно просто нажать
      Enter, чтобы пропустить этот шаг.
      
      3. Перемещение зависимостей
         Если у вас уже есть файл requirements.txt, вы можете импортировать все зависимости из него. Это можно сделать с
         помощью команды:
         poetry add $(cat requirements.txt)
         Это создаст файл pyproject.toml, где будут перечислены ваши зависимости.
      
         4. Установка зависимостей
            После добавления зависимостей вы можете установить их:
            poetry install
            Эта команда создаст виртуальную среду и установит все зависимости, указанные в pyproject.toml.
      
         5. Перенос конфигурации
            Если у вас в проекте есть дополнительные параметры, такие как зависимости разработки или инструменты, укажите их в
            pyproject.toml. Вы можете редактировать этот файл вручную или использовать команды poetry add --dev для добавления
            зависимостей разработки.
      
         6. Использовать виртуальную среду
            poetry управляет виртуальными средами автоматически. Чтобы работать в среде проекта, вам нужно активировать её:
            poetry shell
      
         7. Замена команд pip
            Теперь вы можете использовать команды poetry вместо команд pip. Например:
      
      Для установки пакета:
      poetry add package_name
      
      Для удаления пакета:
      poetry remove package_name
      
      Для обновления пакетов:
      poetry update
      
      Для установки пакетов разработки:
      poetry add --dev package_name
      
      8. Удаление requirements.txt (по желанию)
         Если вы уверены, что всё работает корректно, и вам больше не нужен файл requirements.txt, вы можете удалить его.
      
      Теперь ваш проект полностью использует poetry для управления зависимостями и создания виртуальной среды!
.


                              ДОСТВКА ВИДЕО

CDN

      Если вы используете CDN для доставки видео, 
      DNS будет использоваться для направления пользователей к ближайшему узлу CDN, 
      который может предоставлять контент. 
      Это очень важно для минимизации задержек и улучшения качества стрима.
      
      Существует несколько альтернатив CDN (Content Delivery Network), которые могут использоваться для доставки контента, включая видео, с минимальными задержками и высокой производительностью. Вот некоторые из них:
      
      
      Облачные хранилища:
      
      Amazon S3: Позволяет хранить и доставлять контент, а также интегрируется с Amazon CloudFront для CDN.
      
      Google Cloud Storage: Предоставляет возможность хранения и доставки контента с интеграцией с Google Cloud CDN.
      
      Платформы для стриминга:
      
      Akamai: Один из крупнейших провайдеров CDN, предлагающий решения для стриминга видео.
      
      Cloudflare Stream: Упрощает процесс доставки видео и обеспечивает защиту от DDoS-атак.

.


                              БАЛАНСИРОВКА НАГРУЗКИ НА СЕРВЕРА И ДОСТУП К СЕРВЕРАМ

DNS
      
      Хотя Nginx-RTMP по умолчанию не использует шифрование, он может быть настроен для 
      работы с HLS (HTTP Live Streaming) и DASH (Dynamic Adaptive Streaming over HTTP), 
      которые поддерживают безопасную передачу данных через HTTPS. 
      Убедитесь, что ваш сервер настроен на использование SSL/TLS, что также требует корректной настройки DNS для повышения безопасности.
      
      Существуют различные технологии и сервисы, которые могут дополнить или служить альтернативами DNS (Domain Name System). Вот некоторые из них:
      
      1. Peer-to-Peer (P2P) Системы
      
      IPFS (InterPlanetary File System): Это распределенная система, предназначенная для хранения и распространения данных. IPFS использует уникальные криптографические хэш-адреса, позволяя пользователям находить контент напрямую, минуя традиционные DNS-записи.
      
      Dat Protocol: Протокол, который также позволяет обмениваться данными P2P с использованием уникальных ссылок.
      2. Blockchain Технологии
      
      Ethereum Name Service (ENS): Система доменных имен, которая работает на базе Ethereum и позволяет регистрировать имена, которые могут ссылаться на адреса в блокчейне.
      
      Namecoin: Первая реализация децентрализованной системы доменных имен на основе технологии блокчейн.
      3. Системы маршрутного поиска
      
      MDN (Multicast DNS): Используется в локальных сетях для автоматического обнаружения устройств и сервисов без необходимости использования центрального DNS-сервера.
      
      LLMNR (Link-Local Multicast Name Resolution): Протокол, аналогичный mDNS, используемый для разрешения имен в локальных сетях.
      4. Системы регистрации и управления трафиком
      
      Anycast Routing: Технология, позволяющая использовать один и тот же IP-адрес на нескольких серверах, осуществляя маршрутизацию трафика к ближайшему узлу.
      5. Другие решения
      
      Local Hosts Files: Временные решения для тестирования или разработки, где можно вручную добавлять записи, не используя DNS.
      
      Технологии VPN: Некоторые VPN-сервисы могут предоставлять свои собственные системы разрешения имен, которые могут работать вместо традиционного DNS.
      6. Системы DNS-сервера следующего поколения
      
      DNS over HTTPS (DoH) и DNS over TLS (DoT): Эти технологии обеспечивают более безопасное разрешение доменных имен, защищая запросы от перехвата и манипуляций.
      Каждое из перечисленных решений и технологий имеет свои преимущества и недостатки в зависимости от применяемости, области использования и требований к безопасности и производительности.
.


                                    ХОД РАЗРАБОТКИ

Установил зависимости

Всем __init__ дал __all__ для контроля за import *

Написал аутентификацию с помощью JWT-токенов и библиотеки AuthX. (посмотреть внимательно)
Перенёс config-и для аутентификации с помощью JWT в services.

В пакете database создал async_client и async_db для подключения к Mongo.
Законнектил MongoDBCompass через .env. 

Написал функцию create_access_token --- для генерации Токена
Написал функцию verify_user --- для проверки наличия Токена и ID у юзера в БД, проверки, не истёк ли Токен
Написал функцию registration --- для добавления пользователя в БД 
Написал функцию login --- для авторизации. Проверка creds + добавление Токена + оборачивание Токена в Куки
Написал функцию protected_route --- для перехода по защищённому эндпоинту с предварительной проверкой Куки

create_access_token переместил в services
На основе функии verify_user создал декоратор @verify_user. Переместил в services


У меня есть:
1. --- регистрация (добавление юзера в БД) 
2. --- авторизация (проверка юзера на нахождение в БД + Токен в Куки) [Токен одинаковый для всех юзеров. Не генерится новый]
3. --- аутентификация (проверка прав юзера) 
4. --- логаут (удаление Куки + выход из системы) [Как будто выходит из системы, но Куки не удаляет]
5. --- редиректы при успешных запросах. 303 при GET в принимающем url, 307 при POST в принимающем url



                                    ВАЖНО ПОЧИТАТЬ / ПОДУМАТЬ

Продумать логику авторизации и аутентификации. (схема в draw.io)



Подумать о том, как будет проходить авторизация, какие поля запрашивать у БД? Уникальное поле Почта? 
Может тогда почта будет PK, т.е. - уникальная.

Когда сравниваю пароль юзера при авторизации и пароль, который вытащил из БД - надо хэшировать второй.
И вообще хранить пароль в БД захэшированные. Как это сделать? bcrypt не подкидывается.

JWT токен кодируется, а не хэшируется. Его можно раскодировать. Какие нечувствительные данные можно в нём хранить?
Мне кажется, что id юзера - это чувствительные данные, их можно подделать.
А если спрятать ключ шифрования - можно подделать токен? Сомнительно. 
Можно работать не с JWT, а с Сессиями,
т.к. у меня высоконагруженное приложение, происходит много запросов, а JWT хранят в себе оч много инфы - они большие.
Сессии в несколько раз короче. Надо подумать и, если всё окей - перейти на сессии. 
Сессии хранятся на сервере, а JWT на стороне клиента. C JWT проще

Подумать о том, как хэшировать пароль при добавлении в БД и как проверять при авторизации. Расхэшировать нельзя.

Решить вопрос с подкидыванием нового куки во время авторизации при удалении старого юзером или через /logout

Apache Kafka будет юзаться как основная шина для передачи данных между микросервисами. Возможно, как сборщик логов
с серверов для последующей передачи в (куда?)(системы аналитики), возможно, для синхронизации данных между различными
системами или БД, возможно, для обработки транзакций.

Почитать для себя о корутинах и декораторах в пайтон. Как они связаны?


                                    НА СЛЕД ДЕНЬ


Почитать о Apache Kafka
Начать писать Streaming, связывать микросервисы через Kafka

Задача во время чтения о Kafka:
    В общих словах понять как работает Kafka на верхнем уровне
    Понять, как работает с БД
    Поверхностно изучить методы 
    Найти интеграцию с Python
    Найти интеграцию с MongoDB
    Изучить внутреннюю структуру Kafka

Посмотреть как загонять микросервис в Docker с помощью docker-compose.yml и разрабатывать сразу несколько